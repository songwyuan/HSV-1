# HSV-1

## ç›®å½•å‡†å¤‡
```
#åˆ›å»ºä¸»ç—…æ¯’ç›®å½•ç»“æ„ï¼ˆå¦‚æœå°šä¸å­˜åœ¨ï¼‰

mkdir -p /mnt/alamo01/users/yuansongwei7/download_dna/HSV-1/U87MG

#ä¸ºä¸¤ä¸ªGSEé¡¹ç›®åˆ›å»ºæ ‡å‡†åŒ–ç›®å½•

for gse in GSE235568; do
    mkdir -p /mnt/alamo01/users/yuansongwei7/download_dna/HSV-1//U87MG/${gse}/{scripts,raw_sra,fastq_files,fastqc_results,cleaned_data,alignment_results,analysis_results,logs}
done
```

##  download_GSE237079(GSE236646)
```
#!/bin/bash
set -euo pipefail
#è®¾ç½®ç¯å¢ƒå˜é‡
export PATH="/mnt/alamo01/users/chenyun730/micromamba/envs/sra-tools/bin:$PATH"
BASE_DIR="/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1/GSE236646"
mkdir -p "${BASE_DIR}"/{raw_sra,fastq_files,fastqc_results,logs}

#æ ·æœ¬åˆ—è¡¨ï¼ˆæŒ‰å®éªŒæ¡ä»¶åˆ†ç»„ï¼‰

MOI_0001=(
    SRR25181599 SRR25181600 SRR25181601  # Day3
    SRR25181588 SRR25181589 SRR25181590  # Day5
    SRR25181560 SRR25181561 SRR25181562  # Day7
)

MOI_001=(
    SRR25181585 SRR25181586 SRR25181587  # Day3
    SRR25181564 SRR25181594 SRR25181595  # Day5
    SRR25181557 SRR25181558 SRR25181559  # Day7
)

UNINFECTED=(
    SRR25181571 SRR25181580 SRR25181581  # Day3å¯¹ç…§
    SRR25181568 SRR25181569 SRR25181570  # Day5å¯¹ç…§
    SRR25181574 SRR25181575 SRR25181576  # Day7å¯¹ç…§
)

ALL_SRR=("${MOI_0001[@]}" "${MOI_001[@]}" "${UNINFECTED[@]}")

#ä¸»å¤„ç†å‡½æ•°
process_sample() {
    local srr="$1"
    local log_file="${BASE_DIR}/logs/${srr}.log"

    echo "[$(date '+%Y-%m-%d %H:%M:%S')] START ${srr}" | tee -a "${log_file}"

    # 1. ä¸‹è½½SRAï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    if [[ ! -f "${BASE_DIR}/raw_sra/${srr}.sra" ]]; then
        for attempt in {1..3}; do
            echo "Download attempt ${attempt}" | tee -a "${log_file}"
            if wget -O "${BASE_DIR}/raw_sra/${srr}.sra" \
               "https://sra-pub-run-odp.s3.amazonaws.com/sra/${srr}/${srr}" \
               2>> "${log_file}"; then
                break
            else
                rm -f "${BASE_DIR}/raw_sra/${srr}.sra"
                sleep $((attempt * 10))
            fi
        done
    fi

    # 2. è½¬æ¢FASTQ
    if [[ ! -f "${BASE_DIR}/fastq_files/${srr}_1.fastq.gz" ]]; then
        echo "Converting to FASTQ" | tee -a "${log_file}"
        fastq-dump --split-files "${BASE_DIR}/raw_sra/${srr}.sra" \
            --outdir "${BASE_DIR}/fastq_files" \
            --gzip \
            --skip-technical \
            --dumpbase \
            >> "${log_file}" 2>&1

        # éªŒè¯è¾“å‡º
        if [[ ! -f "${BASE_DIR}/fastq_files/${srr}_1.fastq.gz" ]]; then
            echo "ERROR: FASTQ conversion failed" | tee -a "${log_file}"
            exit 1
        fi
    fi

    # 3. è´¨æ§
    if [[ ! -f "${BASE_DIR}/fastqc_results/${srr}_1_fastqc.html" ]]; then
        echo "Running FastQC" | tee -a "${log_file}"
        fastqc -t 4 \
            "${BASE_DIR}/fastq_files/${srr}_1.fastq.gz" \
            "${BASE_DIR}/fastq_files/${srr}_2.fastq.gz" \
            -o "${BASE_DIR}/fastqc_results" \
            >> "${log_file}" 2>&1
    fi

    # æ¸…ç†åŸå§‹æ•°æ®ï¼ˆä¿ç•™æ³¨é‡Šï¼ŒæŒ‰éœ€å¯ç”¨ï¼‰
    # rm -f "${BASE_DIR}/raw_sra/${srr}.sra"

    echo "[$(date '+%Y-%m-%d %H:%M:%S')] FINISHED ${srr}" | tee -a "${log_file}"
}

#ä¸»ç¨‹åºï¼ˆå¹¶è¡Œæ§åˆ¶ï¼‰
MAX_JOBS=8
for srr in "${ALL_SRR[@]}"; do
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        sleep 10
    done
    process_sample "$srr" &
done

wait  # ç­‰å¾…æ‰€æœ‰åå°ä»»åŠ¡å®Œæˆ

#ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
echo "[$(date '+%Y-%m-%d %H:%M:%S')] Generating MultiQC report"
multiqc "${BASE_DIR}/fastqc_results" -o "${BASE_DIR}/fastqc_results" \
    > "${BASE_DIR}/logs/multiqc.log" 2>&1

#æœ€ç»ˆæ ¡éªŒ
echo "[$(date '+%Y-%m-%d %H:%M:%S')] Validation"
ls -lh "${BASE_DIR}"/fastq_files/*.gz | wc -l | \
    tee -a "${BASE_DIR}/logs/summary.log"
echo "Total samples processed: ${#ALL_SRR[@]}" \
    | tee -a "${BASE_DIR}/logs/summary.log"å…¥çœ -

echo "[$(date '+%Y-%m-%d %H:%M:%S')] ALL DONE"
```


## pinepline.sh(paired_all_paired.sh)
```
$ cat RNAseq_pipeline_PE.sh
#!/bin/bash

########################################
# RNA-seq è‡ªåŠ¨æµç¨‹ï¼ˆé€‚ç”¨äºå¤šç›®å½• PE æ•°æ®ï¼‰
# ä½œè€…: ChatGPT + Yuansongwei7
########################################

# -------- å‚æ•°è®¾ç½® --------
RAW_DIR="/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1"  # åŸå§‹æ•°æ®æ ¹ç›®å½•ï¼ˆé€’å½’ï¼‰
WORK_DIR="/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1_pipeline_output"
CLEAN_DIR="$WORK_DIR/clean_reads"
ALIGN_DIR="$WORK_DIR/alignment"
QC_DIR="$WORK_DIR/qc"
combine_symbol_counts="/mnt/alamo01/projects/Group_Wang/script/function/combine_symbol_counts_STAR.R"

Species="Homo sapiens"
REF="/mnt/alamo01/users/yuansongwei7/genome_index/hg38/star_index"
GTF="/mnt/alamo01/users/yuansongwei7/genome_index/hg38/gencode.v43.annotation.gtf"

THREADS=64
featurecount_thread=32
FASTP_THREADS=64
use_R="/mnt/alamo01/users/chenyun730/micromamba/envs/R441/bin/Rscript"

# -------- åˆ›å»ºç›®å½• --------
mkdir -p $WORK_DIR $QC_DIR $CLEAN_DIR $ALIGN_DIR

# -------- Step 1: æŸ¥æ‰¾æ‰€æœ‰æ ·æœ¬ --------
echo "ğŸ” æ­£åœ¨æŸ¥æ‰¾æ‰€æœ‰åŒç«¯ FASTQ æ–‡ä»¶..."
find $RAW_DIR -type f -name "*_1.fastq.gz" | while read F1; do
    F2=${F1/_1.fastq.gz/_2.fastq.gz}
    if [ ! -f "$F2" ]; then
        echo "âš ï¸ ç¼ºå¤±é…å¯¹æ–‡ä»¶: $F2ï¼Œè·³è¿‡ï¼"
        continue
    fi

    SAMPLE=$(basename "$F1")
    SAMPLE=${SAMPLE%%_1.fastq.gz}

    echo "ğŸ¯ å¤„ç†æ ·æœ¬: $SAMPLE"

    # ---- Step 1: Fastp æ¸…æ´— ----
    CLEAN_R1="$CLEAN_DIR/${SAMPLE}_clean_R1.fq.gz"
    CLEAN_R2="$CLEAN_DIR/${SAMPLE}_clean_R2.fq.gz"
    DONE_FLAG="$CLEAN_DIR/${SAMPLE}.done"

    if [ -f "$DONE_FLAG" ]; then
        echo "â© [$SAMPLE] å·²æ¸…æ´—ï¼Œè·³è¿‡"
    else
        echo "ğŸ§¼ æ­£åœ¨æ¸…æ´— [$SAMPLE] ..."
        fastp -i "$F1" -I "$F2" -o "$CLEAN_R1" -O "$CLEAN_R2" \
            --detect_adapter_for_pe -q 25 -u 20 -e 20 -r -W 5 -M 30 \
            --length_required 50 -h "$CLEAN_DIR/${SAMPLE}.html" \
            -j "$CLEAN_DIR/${SAMPLE}.json" -w $FASTP_THREADS > "$CLEAN_DIR/${SAMPLE}_fastp.log" 2>&1

        if [ $? -eq 0 ]; then
            touch "$DONE_FLAG"
            echo "âœ… [$SAMPLE] fastp å®Œæˆ"
        else
            echo "âŒ [$SAMPLE] fastp å¤±è´¥" | tee "$CLEAN_DIR/${SAMPLE}.error"
            continue
        fi
    fi

    # ---- Step 2: æ¯”å¯¹ ----
    ALIGN_SAMPLE_DIR="$ALIGN_DIR/$SAMPLE"
    mkdir -p "$ALIGN_SAMPLE_DIR"
    cd "$ALIGN_SAMPLE_DIR"

    ALIGN_DONE="$ALIGN_SAMPLE_DIR/${SAMPLE}.align.done"
    FEATURE_DONE="$ALIGN_SAMPLE_DIR/${SAMPLE}.feature.done"

    # ---- Step 2: æ¯”å¯¹ ----
    if [ ! -f "$ALIGN_DONE" ]; then
        echo "ğŸ§¬ [$SAMPLE] STAR æ¯”å¯¹ä¸­..."
        STAR --runThreadN $THREADS \
            --genomeDir $REF \
            --readFilesIn "$CLEAN_R1" "$CLEAN_R2" \
            --readFilesCommand zcat \
            --outFileNamePrefix "${SAMPLE}_" \
            --outSAMtype BAM SortedByCoordinate \
            --outSAMattributes NH HI AS nM NM MD \
            --outFilterMultimapNmax 10 --outFilterMismatchNmax 5 \
            --outFilterScoreMinOverLread 0.8 \
            --alignIntronMin 20 --alignIntronMax 1000000 \
            --alignMatesGapMax 1000000 \
            --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \
            --sjdbScore 1 --twopassMode Basic \
            --twopass1readsN -1 --quantMode GeneCounts > star.log 2>&1

        if [ $? -eq 0 ]; then
            echo "âœ… [$SAMPLE] STAR æ¯”å¯¹å®Œæˆ"
            touch "$ALIGN_DONE"
        else
            echo "âŒ [$SAMPLE] STAR æ¯”å¯¹å¤±è´¥" | tee "${SAMPLE}.error"
            continue
        fi
    else
        echo "â© [$SAMPLE] å·²æ¯”å¯¹ï¼Œè·³è¿‡æ¯”å¯¹æ­¥éª¤"
    fi

    # ---- Step 3: featureCounts å®šé‡ ----
    if [ ! -f "$FEATURE_DONE" ]; then
        echo "ğŸ“ [$SAMPLE] featureCounts å®šé‡ä¸­..."
        featureCounts -p -B -C -T $featurecount_thread -a $GTF \
            -o "${SAMPLE}_gene_counts.txt" "${SAMPLE}_Aligned.sortedByCoord.out.bam" > featurecounts.log 2>&1
        if [ $? -eq 0 ]; then
            echo "âœ… [$SAMPLE] featureCounts å®Œæˆ"
            touch "$FEATURE_DONE"
        else
            echo "âŒ [$SAMPLE] featureCounts å¤±è´¥" | tee "${SAMPLE}.feature.error"
        fi
    else
        echo "â© [$SAMPLE] å·²å®Œæˆ featureCountsï¼Œè·³è¿‡"
    fi


    cd - > /dev/null
done

# -------- Step 4: æ•´åˆè¡¨è¾¾çŸ©é˜µ --------
echo "ğŸ“Š æ±‡æ€»æ‰€æœ‰åŸºå› è¡¨è¾¾çŸ©é˜µ..."
cd "$ALIGN_DIR"
$use_R $combine_symbol_counts "$ALIGN_DIR" "$Species" "$GTF"
echo "âœ… è¡¨è¾¾çŸ©é˜µæ•´åˆå®Œæˆ"

echo "ğŸ‰ å…¨éƒ¨åˆ†ææµç¨‹ç»“æŸï¼"


```
#å•ç«¯æ•°æ®åˆ†æ
```
#!/bin/bash

########################################
# è‡ªåŠ¨åŒ– RNA-seq æµç¨‹ï¼ˆå•ç«¯ç‰ˆï¼‰
# FastQC â†’ fastp â†’ STAR + featureCounts â†’ gene count matrix
# ä½œè€…: ChatGPT + Yuansongwei7ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
########################################

# -------- å‚æ•°è®¾ç½® --------
RAW_DIR="/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1"
WORK_DIR="/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1_pipeline_output_single"
CLEAN_DIR="$WORK_DIR/clean_reads"
ALIGN_DIR="$WORK_DIR/alignment"
QC_DIR="$WORK_DIR/qc"

Species="Homo sapiens"
REF="/mnt/alamo01/users/yuansongwei7/genome_index/hg38/star_index"
GTF="/mnt/alamo01/users/yuansongwei7/genome_index/hg38/gencode.v43.annotation.gtf"
combine_symbol_counts="/mnt/alamo01/users/yuansongwei7/scripts/combine_symbol_counts_STAR.R"
use_R="/mnt/alamo01/users/chenyun730/micromamba/envs/R441/bin/Rscript"

THREADS=64
FASTP_THREADS=64
featurecount_thread=32

mkdir -p $WORK_DIR $QC_DIR $CLEAN_DIR $ALIGN_DIR

########################################
# Step 1: FastQC + MultiQC
########################################
echo "ğŸ“Š Step 1: Running FastQC..."
QC_REPORT="$QC_DIR/raw/multiqc_report.html"
if [ -f "$QC_REPORT" ]; then
    echo "âœ… QAæŠ¥å‘Šå·²å­˜åœ¨ï¼Œè·³è¿‡FastQCä¸MultiQCï¼š$QC_REPORT"
else
    mkdir -p $QC_DIR/raw
    fastqc -o $QC_DIR/raw -t $THREADS $RAW_DIR/*.fastq.gz
    multiqc -o $QC_DIR/raw $QC_DIR/raw
    echo "âœ… FastQCä¸MultiQCå®Œæˆï¼"
fi

########################################
# Step 2: fastp æ¸…æ´—ï¼ˆå•ç«¯ï¼‰
########################################
echo "ğŸ§¼ Step 2: Cleaning reads with fastp..."
for fq in $RAW_DIR/*.fastq.gz; do
    SAMPLE=$(basename "$fq" .fastq.gz)
    DONE_FLAG="$CLEAN_DIR/${SAMPLE}.done"

    # è·³è¿‡åŒç«¯æ•°æ®ï¼ˆ*_1.fastq.gz / *_2.fastq.gzï¼‰
    if [[ "$fq" =~ _[12]\.fastq\.gz$ ]]; then
        echo "âš ï¸ æ£€æµ‹åˆ°åŒç«¯æ–‡ä»¶ [$fq]ï¼Œè·³è¿‡"
        continue
    fi

    if [ -f "$DONE_FLAG" ]; then
        echo "â© [$SAMPLE] å·²å®Œæˆ fastpï¼Œè·³è¿‡"
        continue
    fi

    echo "ğŸ§¹ [$SAMPLE] fastp æ¸…æ´—..."
    if fastp -i "$fq" -o "$CLEAN_DIR/${SAMPLE}_clean.fq.gz" \
        -q 25 -u 20 -e 20 -r -W 5 -M 30 \
        --length_required 50 \
        -h "$CLEAN_DIR/${SAMPLE}.html" \
        -j "$CLEAN_DIR/${SAMPLE}.json" \
        -w $FASTP_THREADS > "$CLEAN_DIR/${SAMPLE}_fastp.log" 2>&1; then
        touch "$DONE_FLAG"
        echo "âœ… [$SAMPLE] fastp å®Œæˆ"
    else
        echo "âŒ [$SAMPLE] fastp å¤±è´¥"
    fi
done

# fastp QC åˆå¹¶
QC_REPORT2="$CLEAN_DIR/multiqc_report.html"
if [ ! -f "$QC_REPORT2" ]; then
    multiqc $CLEAN_DIR -o $CLEAN_DIR
fi

########################################
# Step 3: STAR + featureCounts
########################################
echo "ğŸ§¬ Step 3: STAR + featureCounts..."
for fq in $CLEAN_DIR/*_clean.fq.gz; do
    SAMPLE=$(basename "$fq" _clean.fq.gz)
    ALIGN_SAMPLE_DIR=$ALIGN_DIR/$SAMPLE
    DONE_FLAG="$ALIGN_SAMPLE_DIR/${SAMPLE}.done"

    if [ -f "$DONE_FLAG" ]; then
        echo "â© [$SAMPLE] å·²å®Œæˆæ¯”å¯¹ï¼Œè·³è¿‡"
        continue
    fi

    mkdir -p $ALIGN_SAMPLE_DIR
    cd $ALIGN_SAMPLE_DIR

    echo "ğŸ§¬ [$SAMPLE] STAR æ¯”å¯¹..."
    if STAR --runThreadN $THREADS \
        --genomeDir $REF \
        --readFilesIn "$fq" \
        --readFilesCommand zcat \
        --outFileNamePrefix "${SAMPLE}_" \
        --outSAMtype BAM SortedByCoordinate \
        --outSAMattributes NH HI AS nM NM MD \
        --outFilterMultimapNmax 10 --outFilterMismatchNmax 5 \
        --outFilterScoreMinOverLread 0.8 \
        --alignIntronMin 20 --alignIntronMax 1000000 \
        --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \
        --sjdbScore 1 --twopassMode Basic \
        --twopass1readsN -1 --quantMode GeneCounts > star.log 2>&1; then
        echo "âœ… [$SAMPLE] STAR å®Œæˆ"

        echo "ğŸ§® [$SAMPLE] featureCounts..."
        featureCounts -T $featurecount_thread -a $GTF \
            -o "${SAMPLE}_gene_counts.txt" "${SAMPLE}_Aligned.sortedByCoord.out.bam" > featurecounts.log 2>&1
        echo "âœ… [$SAMPLE] featureCounts å®Œæˆ"

        touch "$DONE_FLAG"
    else
        echo "âŒ [$SAMPLE] STAR å¤±è´¥"
    fi
    cd - > /dev/null
done

########################################
# Step 4: è¡¨è¾¾çŸ©é˜µæ•´åˆ
########################################
echo "ğŸŸ¢ Step 4: åˆå¹¶åŸºå› è¡¨è¾¾çŸ©é˜µ..."
cd $ALIGN_DIR
$use_R $combine_symbol_counts "$ALIGN_DIR" "$Species" "$GTF"
echo "âœ… gene symbol èšåˆå®Œæˆï¼"

########################################
echo "ğŸ‰ æ‰€æœ‰æ ·æœ¬æµç¨‹å®Œæˆï¼"

```

#combine_symbol_counts.R

```
#!/usr/bin/env Rscript

suppressMessages(library(dplyr))
suppressMessages(library(biomaRt))
suppressMessages(library(GenomicFeatures))
suppressMessages(library(txdbmaker))

# è·å–å‘½ä»¤è¡Œå‚æ•°ï¼ˆå»æ‰ Rscript è·¯å¾„æœ¬èº«ï¼‰
args <- commandArgs(trailingOnly = TRUE)

if (length(args) < 2) {
  stop("âŒ è¯·è¾“å…¥ alignmentä¸ç‰©ç§ä¿¡æ¯ ä¸¤ä¸ªå‚æ•°")
}

align_path <- args[1]
species = args[2]
gtf_path = args[3]

if(species == "Homo sapiens") {
  ensembl = useMart("ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl")
  symbol = "hgnc_symbol"
}else if(species == "Mus musculus"){
  ensembl = useMart("ENSEMBL_MART_ENSEMBL", dataset = "mmusculus_gene_ensembl")
  symbol = "mgi_symbol"
}

# è·å–æ‰€æœ‰featureCountsè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„
files <- list.files(pattern = "gene_counts.txt$",path = align_path,recursive = T)

# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„æ•°æ®æ¡†ï¼Œç”¨äºå­˜å‚¨åŸºå› è®¡æ•°çŸ©é˜µ
gene_counts <- data.frame()

# éå†æ¯ä¸ªæ–‡ä»¶ï¼Œè¯»å–æ•°æ®å¹¶åˆå¹¶
for (file in files) {
  # è¯»å–æ¯ä¸ªfeatureCountsçš„è¾“å‡ºæ–‡ä»¶
  count_data <- read.table(file, header = TRUE, sep = "\t", comment.char = "#",check.names = F)
  
  # æå–Gene IDå’Œè®¡æ•°åˆ—ï¼Œç¡®ä¿è®¡æ•°åˆ—åç§°ä¸º"Count"
  count_data_subset <- count_data[, c(1,7)]
  
  # å°†Gene IDåˆ—ä½œä¸ºè¡Œå
  rownames(count_data_subset) <- count_data_subset$Geneid
  
  # åˆ é™¤Geneidåˆ—ï¼Œå› ä¸ºå®ƒå·²ç»ä½œä¸ºè¡Œå
  count_data_subset$Geneid <- NULL
  
  # è·å–æ ·æœ¬åç§°ä½œä¸ºåˆ—å
  sample_name <- strsplit(file,"\\/")[[1]][1]  # ä»æ–‡ä»¶åä¸­æå–æ ·æœ¬åç§°
  
  # åˆå¹¶æ•°æ®
  if (ncol(gene_counts) == 0) {
    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡åˆå¹¶ï¼Œç›´æ¥å°†æ•°æ®æ”¾å…¥gene_counts
    gene_counts <- count_data_subset
    colnames(gene_counts) <- sample_name
  } else {
    # å¦åˆ™ï¼Œå°†å½“å‰æ ·æœ¬çš„è®¡æ•°æ•°æ®æ·»åŠ åˆ°gene_countsçŸ©é˜µä¸­
    gene_counts <- cbind(gene_counts, count_data_subset)
    colnames(gene_counts)[ncol(gene_counts)] <- sample_name
  }
}

# ä¿å­˜åˆå¹¶åçš„åŸºå› è¡¨è¾¾çŸ©é˜µ
write.csv(gene_counts, "transcript_count_matrix.csv", quote = FALSE, row.names = TRUE)

# ä½¿ç”¨biomaRtæŸ¥è¯¢Gene Symbol
gene_symbols <- getBM(attributes = c('ensembl_gene_id', symbol),
                      filters = 'ensembl_gene_id',
                      values = rownames(gene_counts),
                      mart = ensembl)
colnames(gene_symbols)[2] <- "symbol"

# å°†Gene Symbolåˆå¹¶åˆ°åŸºå› è®¡æ•°çŸ©é˜µä¸­
gene_counts$GeneSymbol <- gene_symbols[,2][match(rownames(gene_counts), gene_symbols$ensembl_gene_id)]

# èšåˆ & æ¸…ç†
gene_counts <- gene_counts[-which(gene_counts$GeneSymbol == ""),]
gene_counts <- na.omit(gene_counts)
gene_matrix <- gene_counts %>%
  group_by(GeneSymbol) %>%
  summarise(across(where(is.numeric), sum)) %>%
  as.data.frame()

rownames(gene_matrix) <- gene_matrix$GeneSymbol
gene_matrix <- gene_matrix[, -1]

# è¾“å‡º
write.csv(gene_matrix, "gene_count_matrix_symbol_merged.csv", quote = FALSE)
cat("âœ… Symbol Countèšåˆå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶ï¼š", paste(align_path,"gene_count_matrix_symbol_merged.csv",sep = "/"), "\n")

####

# 1. å»ºç«‹TxDbå¯¹è±¡ï¼ŒGTFæ–‡ä»¶è·¯å¾„æ ¹æ®ä½ å®é™…ä½ç½®ä¿®æ”¹
txdb <- makeTxDbFromGFF(gtf_path, format="gtf")

# 2. æå–åŸºå› çš„å¤–æ˜¾å­åŒº
exonsByGene <- exonsBy(txdb, by="gene")

# 3. è®¡ç®—æ¯ä¸ªåŸºå› å¤–æ˜¾å­çš„å®½åº¦æ€»å’Œï¼ˆåˆå¹¶é‡å ï¼‰
gene_lengths <- sum(width(reduce(exonsByGene)))

# 4. è½¬æˆæ•°æ®æ¡†ï¼Œgene_id å’Œ length
gene_length_df <- data.frame(
  ensembl = names(gene_lengths),
  length = as.numeric(gene_lengths)
)

gene_length_df <- left_join(gene_length_df, gene_symbols, by = c("ensembl" = "ensembl_gene_id")) %>%
  filter(symbol != "") %>%  # å»é™¤æ²¡æœ‰ symbol çš„
  group_by(symbol) %>%
  summarise(symbol_length = mean(length))

symbol_lengths <- gene_length_df$symbol_length
names(symbol_lengths) <- gene_length_df$symbol

use_gene <- intersect(gene_length_df$symbol,rownames(gene_matrix))

rpk <- sweep(gene_matrix[use_gene,], 1, symbol_lengths[use_gene] / 1000, "/")

tpm <- sweep(rpk, 2, colSums(rpk), "/") * 1e6

# è¾“å‡º
write.csv(tpm, "gene_tpm_matrix_symbol_merged.csv", quote = FALSE)
cat("âœ… Symbol TPMèšåˆå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶ï¼š", paste(align_path,"gene_tpm_matrix_symbol_merged.csv",sep = "/"), "\n")

```

# extractjson
```
#!/bin/env Rscript
# ä¿®è®¢ç‚¹ï¼š
# 1) è·¯å¾„æ”¹åˆ°ä½ çš„ pipeline è¾“å‡ºï¼šPAIRED ä¸ SINGLE åˆ†åˆ«æŒ‡å‘ HSV-1_pipeline_output / HSV-1_pipeline_output_single
# 2) ä¿®å¤ unknown/na åˆ¤æ–­ï¼›ä¿®å¤ TPM åˆ—ååŒ¹é…å˜é‡é”™è¯¯ï¼›å¢åŠ åˆ—ç¼ºå¤±å‘Šè­¦
# 3) å…è®¸ LibraryLayout å¤§å°å†™å·®å¼‚ï¼ˆPAIRED / SINGLE / SINGLE-ENDï¼‰

Sys.setenv(TMPDIR = "/mnt/alamo01/projects/Group_Wang/sampledata/tmp_r")

args <- commandArgs(trailingOnly = TRUE)
if (length(args) != 1) {
  stop("âŒ Usage: Rscript generate_metadata_batch_from_table.R <input_csv_path>")
}

suppressPackageStartupMessages({
  library(jsonlite)
  library(readr)
  library(stringr)
  library(dplyr)
  library(fs)
})

input_csv <- args[1]
df <- read_csv(input_csv, show_col_types = FALSE)

# ---- ä½ çš„ pipeline è¾“å‡ºæ ¹ç›®å½•ï¼ˆæŒ‰ LibraryLayout é€‰æ‹©ï¼‰ ----
PAIRED_ALIGN_DIR <- "/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1_pipeline_output/alignment"
SINGLE_ALIGN_DIR <- "/mnt/alamo01/users/yuansongwei7/download_dna/HSV-1_pipeline_output_single/alignment"

# å°å·¥å…·ï¼šæ ‡å‡†åŒ– layout
norm_layout <- function(x){
  lx <- toupper(str_trim(as.character(x)))
  if (lx %in% c("PAIRED", "PE")) return("PAIRED")
  if (lx %in% c("SINGLE", "SE", "SINGLE-END", "SINGLE END")) return("SINGLE")
  return(lx)
}

for (i in seq_len(nrow(df))) {
  row <- df[i, ]

  number        <- sprintf("%03d", row$Number)
  accession     <- row$Accession
  virus         <- row$Virus
  cell_line     <- row$CellLine
  raw_time      <- row$`Infection Time`
  moi_str       <- row$VirusDose
  library_layout<- norm_layout(row$LibraryLayout)
  species       <- row$Species
  strain        <- row$VirusStrain
  safe_strain   <- fs::path_sanitize(strain, replacement = "_")

  # ---- è§„èŒƒåŒ– infection_time / MOI ----
  raw_time_lc <- tolower(str_trim(as.character(raw_time)))
  infection_time <- if (str_detect(raw_time_lc, "unknown|unkown|na|n/a")) "unknown" else toupper(str_trim(as.character(raw_time)))

  moi_lc <- tolower(str_trim(as.character(moi_str)))
  MOI <- if (str_detect(moi_lc, "unknown|unkown|na|n/a")) "unknown" else str_extract(as.character(moi_str), "[0-9.]+")
  if (is.na(MOI) || MOI == "") MOI <- "unknown"

  # ---- è¾“å‡º JSON ç›®å½• ----
  time_moi <- paste0(infection_time, "_MOI", MOI)
  json_out_dir <- file.path("/mnt/alamo01/projects/Group_Wang/sampledata", virus, cell_line, paste0(time_moi, "_", accession, "_", safe_strain))
  dir_create(json_out_dir)

  # ---- è§£æåˆ†ç»„ ID ----
  split_ids <- function(x){
    if (is.null(x) || is.na(x)) return(character(0))
    unlist(str_split(x, "\\s*[,\\n]\\s*"))
  }
  mock_gsm      <- split_ids(row$Mock)
  infected_gsm  <- split_ids(row$Infected)
  SRR_mock      <- split_ids(row$SRR_mock)
  SRR_infected  <- split_ids(row$SRR_infected)

  # ---- å…ƒæ•°æ® JSON ----
  version <- paste0("R-", R.version$major, ".", R.version$minor)
  today <- Sys.Date()
  metadata <- list(
    experiment = list(
      virus = virus,
      type = row$Type,
      cell_line = cell_line,
      strain = strain,
      infection_time = infection_time,
      MOI = MOI,
      LibraryLayout = library_layout,
      replicates = row$Replicates,
      control_condition = "Mock",
      Mock = mock_gsm,
      Infected = infected_gsm,
      SRR_mock = SRR_mock,
      SRR_infected = SRR_infected
    ),
    data_source = list(
      gse = accession,
      comparison = paste("Mock vs Infected ", row$Virus, "(", row$VirusStrain, ")", sep = ""),
      organism = species,
      reference = paste0("https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=", accession)
    ),
    analysis = list(
      tool = "DESeq2",
      version = version,
      date = as.character(today),
      parameters = list(
        pvalue_cutoff = 0.05,
        log2fc_cutoff = 1,
        normalization = "rlog"
      )
    )
  )
  json_path <- file.path(json_out_dir, "meta_analysis_info.json")
  write_json(metadata, json_path, pretty = TRUE, auto_unbox = TRUE)
  message("âœ… JSON written: ", json_path)

  # ---- é€‰æ‹©çŸ©é˜µæ–‡ä»¶ï¼šæŒ‰ LibraryLayout èµ°ä½ å½“å‰ pipeline çš„è¾“å‡º ----
  align_dir <- if (library_layout == "PAIRED") PAIRED_ALIGN_DIR else SINGLE_ALIGN_DIR
  matrix_path <- file.path(align_dir, "gene_count_matrix_symbol_merged.csv")
  tpm_path    <- file.path(align_dir, "gene_tpm_matrix_symbol_merged.csv")

  if (!file.exists(matrix_path)) {
    message("âŒ Matrix not found at: ", matrix_path, "  (layout=", library_layout, ")  è·³è¿‡è¯¥è¡Œ")
    next
  }
  if (!file.exists(tpm_path)) {
    message("âŒ TPM matrix not found at: ", tpm_path, "  (layout=", library_layout, ")  è·³è¿‡è¯¥è¡Œ")
    next
  }

  # ---- é€‰æ‹©ä½¿ç”¨ GSM è¿˜æ˜¯ SRR ----
  use_gsm <- length(SRR_mock) > 0 && all(tolower(SRR_mock) == "merged")
  if (use_gsm) {
    mock_ids     <- mock_gsm
    infected_ids <- infected_gsm
  } else {
    mock_ids     <- SRR_mock
    infected_ids <- SRR_infected
  }
  # å…œåº•ï¼šéƒ½ä¸ºç©ºæ—¶æç¤ºå¹¶è·³è¿‡
  if (length(c(mock_ids, infected_ids)) == 0) {
    message("âŒ No sample IDs (GSM/SRR) provided for accession: ", accession, "  è·³è¿‡è¯¥è¡Œ")
    next
  }

  # ---- è¯»å–ä¸æŒ‘åˆ—ï¼šCounts ----
  count_matrix <- read_csv(matrix_path, show_col_types = FALSE)
  # ç¬¬ä¸€åˆ—æ”¹åä¸º Gene
  if (ncol(count_matrix) > 0) {
    names(count_matrix)[1] <- "Gene"
  }
  colnames_to_extract <- unique(c(mock_ids, infected_ids))
  found_cols_counts <- intersect(colnames(count_matrix), colnames_to_extract)
  if (length(found_cols_counts) == 0) {
    message("âš ï¸ None of requested columns found in COUNT matrix for ", accession, "  (IDs: ", paste(colnames_to_extract, collapse=", "), ")")
  }
  expression_matrix <- count_matrix %>% select(any_of(c("Gene", found_cols_counts)))
  expression_out_path <- file.path(json_out_dir, "count_matrix.csv")
  write_csv(expression_matrix, expression_out_path)

  # ---- è¯»å–ä¸æŒ‘åˆ—ï¼šTPMï¼ˆä¿®æ­£ï¼šç”¨ tpm_matrix çš„åˆ—ååŒ¹é…ï¼‰----
  tpm_matrix <- read_csv(tpm_path, show_col_types = FALSE)
  if (ncol(tpm_matrix) > 0) {
    names(tpm_matrix)[1] <- "Gene"
  }
  found_cols_tpm <- intersect(colnames(tpm_matrix), colnames_to_extract)
  if (length(found_cols_tpm) == 0) {
    message("âš ï¸ None of requested columns found in TPM matrix for ", accession)
  }
  expression_tpm_matrix <- tpm_matrix %>% select(any_of(c("Gene", found_cols_tpm)))
  tpm_out_path <- file.path(json_out_dir, "tpm_matrix.csv")
  write_csv(expression_tpm_matrix, tpm_out_path)

  # ---- ç»„ä¿¡æ¯ JSON ----
  rld_metadata <- list(Mock = mock_ids, Infected = infected_ids)
  rld_json_path <- file.path(json_out_dir, "meta_group_info.json")
  write_json(rld_metadata, rld_json_path, pretty = TRUE, auto_unbox = TRUE)

  message("ğŸ“Š Saved: ", expression_out_path, " | ", tpm_out_path, " | ", rld_json_path)
}

```



